{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dewizzz/lalalayeyeyelulusfixed?scriptVersionId=142675647\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<a href=\"https://www.kaggle.com/code/dewizzz/lalalayeyeyelulusfixed?scriptVersionId=138655296\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:#F0E68C;font-family:Halvetica;font-size:550%;text-align:center;border-radius: 15px 10px;padding: 5px\"><b>Deteksi Autisme</b></h1>","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport seaborn as sn\nimport pandas as pd\nfrom PIL import Image\nfrom torch import nn, optim\nimport matplotlib.pyplot as plt\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import TensorDataset\nimport torchvision.transforms as transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\n\nfrom tqdm.notebook import tqdm\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:07.665819Z","iopub.execute_input":"2023-09-11T20:06:07.66643Z","iopub.status.idle":"2023-09-11T20:06:07.674399Z","shell.execute_reply.started":"2023-09-11T20:06:07.666395Z","shell.execute_reply":"2023-09-11T20:06:07.673408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Load Data**","metadata":{}},{"cell_type":"code","source":"# Path ke folder kelas 1\nfolder_kelas_1 = '/kaggle/input/data-skripsi/Data Skripsi/Kelas Autisme'\n\n# Path ke folder kelas 0\nfolder_kelas_0 = '/kaggle/input/data-skripsi/Data Skripsi/Kelas TC'\n\n# Inisialisasi dictionary untuk menyimpan label\nlabel_gambar = {}\n\n# Melabeli gambar-gambar dalam folder kelas 1\nfor file in os.listdir(folder_kelas_1):\n    if file.endswith('.gif'):\n        label_gambar[file] = 1  # Label kelas 1\n\n# Melabeli gambar-gambar dalam folder kelas 0\nfor file in os.listdir(folder_kelas_0):\n    if file.endswith('.gif'):\n        label_gambar[file] = 0  # Label kelas 0","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:07.675576Z","iopub.execute_input":"2023-09-11T20:06:07.676104Z","iopub.status.idle":"2023-09-11T20:06:07.701537Z","shell.execute_reply.started":"2023-09-11T20:06:07.676067Z","shell.execute_reply":"2023-09-11T20:06:07.700615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mencetak hasil labeling untuk 5 gambar dari setiap kelas\ncount_kelas_0 = 0\ncount_kelas_1 = 0\n\nfor file, label in label_gambar.items():\n    if label == 0 and count_kelas_0 < 5:\n        print(f\"File: {file}, Label: {label}\")\n        count_kelas_0 += 1\n    elif label == 1 and count_kelas_1 < 5:\n        print(f\"File: {file}, Label: {label}\")\n        count_kelas_1 += 1\n    \n    if count_kelas_0 == 5 and count_kelas_1 == 5:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:07.703934Z","iopub.execute_input":"2023-09-11T20:06:07.704187Z","iopub.status.idle":"2023-09-11T20:06:07.714882Z","shell.execute_reply.started":"2023-09-11T20:06:07.704165Z","shell.execute_reply":"2023-09-11T20:06:07.713508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transformasi untuk data gambar GIF\nclass GIFToTensor(object):\n    def __call__(self, pic):\n        if pic.mode != 'RGB':\n            pic = pic.convert('RGB')\n        return transforms.ToTensor()(pic)\n\n# Transformasi data\ntransform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(210),\n    transforms.Resize(224),\n    GIFToTensor(),\n])\n\n# Proses transformasi dan penyimpanan data\ndata = []\n\nfor file, label in label_gambar.items():\n    # Baca gambar dan aplikasikan transformasi\n    img_path = os.path.join(folder_kelas_1 if label == 1 else folder_kelas_0, file)\n    image = Image.open(img_path)\n    transformed_image = transform(image)\n    \n    # Simpan data dan label ke dalam list\n    data.append((transformed_image, label))","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:07.716523Z","iopub.execute_input":"2023-09-11T20:06:07.716898Z","iopub.status.idle":"2023-09-11T20:06:11.037794Z","shell.execute_reply.started":"2023-09-11T20:06:07.716865Z","shell.execute_reply":"2023-09-11T20:06:11.036734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Split Data**","metadata":{}},{"cell_type":"code","source":"# Bagi data menjadi set pelatihan dan set pengujian\ntrain_data, test_data, train_labels, test_labels = train_test_split(\n    [item[0] for item in data],  # Data gambar\n    [item[1] for item in data],  # Label\n    test_size=0.3,  # Proporsi set pengujian\n    random_state=42  # Seed untuk reproduktibilitas\n)\n\n# Cetak jumlah data dalam set pelatihan dan set pengujian\nprint(f\"Jumlah data pelatihan: {len(train_data)}\")\nprint(f\"Jumlah data pengujian: {len(test_data)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:11.039339Z","iopub.execute_input":"2023-09-11T20:06:11.041432Z","iopub.status.idle":"2023-09-11T20:06:11.051054Z","shell.execute_reply.started":"2023-09-11T20:06:11.041398Z","shell.execute_reply":"2023-09-11T20:06:11.049826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Menampilkan 5 gambar dari set pelatihan\nfig, axes = plt.subplots(1, 5, figsize=(10, 4))\n\nfor i, ax in enumerate(axes):\n    img = train_data[i].permute(1, 2, 0)  # Mengubah dimensi tensor menjadi (H, W, C)\n    label = train_labels[i]\n    ax.imshow(img)\n    ax.set_title(f\"Label: {label}\")\n    ax.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:11.052529Z","iopub.execute_input":"2023-09-11T20:06:11.052941Z","iopub.status.idle":"2023-09-11T20:06:11.57163Z","shell.execute_reply.started":"2023-09-11T20:06:11.052909Z","shell.execute_reply":"2023-09-11T20:06:11.570442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Split Data Train - Val**","metadata":{}},{"cell_type":"markdown","source":"# Memisahkan data pelatihan menjadi data validasi dan data pelatihan baru\ntrain_data, val_data, train_labels, val_labels = train_test_split(\n    train_data,  # Data pelatihan yang sudah ada\n    train_labels,  # Label pelatihan yang sudah ada\n    test_size=0.3,  # Proporsi data validasi\n    random_state=42  # Seed untuk reproduktibilitas\n)\n\n# Cetak jumlah data dalam set pelatihan dan set pengujian\nprint(f\"Jumlah data pelatihan: {len(train_data)}\")\nprint(f\"Jumlah data pengujian: {len(val_data)}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-11T13:27:31.919657Z","iopub.execute_input":"2023-09-11T13:27:31.925304Z","iopub.status.idle":"2023-09-11T13:27:31.939142Z","shell.execute_reply.started":"2023-09-11T13:27:31.925265Z","shell.execute_reply":"2023-09-11T13:27:31.938192Z"}}},{"cell_type":"markdown","source":"# Perbaikan pixel (buat jaga-jaga)","metadata":{}},{"cell_type":"code","source":"train_dataset = list(zip(train_data, train_labels))\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n\ntest_dataset = list(zip(test_data, test_labels))\ntest_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:11.573027Z","iopub.execute_input":"2023-09-11T20:06:11.573663Z","iopub.status.idle":"2023-09-11T20:06:11.581767Z","shell.execute_reply.started":"2023-09-11T20:06:11.57363Z","shell.execute_reply":"2023-09-11T20:06:11.580612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Menginisialisasi model pretrained\nmodel = models.vgg16(pretrained=True)\n\n# Menonaktifkan penghitungan gradien untuk parameter model pretrained\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Mengubah ukuran input pada lapisan konvolusi pertama\nmodel.features[0] = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n\n# Mengganti layer terakhir (fully connected) pada model dengan layer baru\nnum_classes = 2  # Jumlah kelas\nmodel.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:11.583564Z","iopub.execute_input":"2023-09-11T20:06:11.584088Z","iopub.status.idle":"2023-09-11T20:06:13.31635Z","shell.execute_reply.started":"2023-09-11T20:06:11.584054Z","shell.execute_reply":"2023-09-11T20:06:13.315276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:13.321189Z","iopub.execute_input":"2023-09-11T20:06:13.323449Z","iopub.status.idle":"2023-09-11T20:06:13.338654Z","shell.execute_reply.started":"2023-09-11T20:06:13.323415Z","shell.execute_reply":"2023-09-11T20:06:13.337318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Menggunakan perangkat GPU jika tersedia\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:13.346707Z","iopub.execute_input":"2023-09-11T20:06:13.347036Z","iopub.status.idle":"2023-09-11T20:06:13.54968Z","shell.execute_reply.started":"2023-09-11T20:06:13.347005Z","shell.execute_reply":"2023-09-11T20:06:13.548558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mendifinisikan fungsi loss dan optimizer\ncriterion = nn.CrossEntropyLoss()\nlearning_rate = 1e-4\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:13.554772Z","iopub.execute_input":"2023-09-11T20:06:13.557245Z","iopub.status.idle":"2023-09-11T20:06:13.56544Z","shell.execute_reply.started":"2023-09-11T20:06:13.557206Z","shell.execute_reply":"2023-09-11T20:06:13.564406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Train Model**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ntrain_loss = []\ntrain_accuracy = []\nvalid_loss = []\nvalid_accuracy = []\n\ndef train(model, device, train_loader, optimizer, epoch, train_indices, log_interval=10000):\n    model.train()\n    tk0 = tqdm(train_loader, total=int(len(train_loader)))\n    counter = 0\n    running_loss = 0.0\n    running_corrects = 0\n    for batch_idx, (data, target) in enumerate(tk0):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data)\n        logits = output\n        output = F.softmax(output, dim=1)\n        _, preds = torch.max(output, dim=1)\n        loss = criterion(logits, target)\n        loss.backward()\n        optimizer.step()\n        counter += 1\n        tk0.set_postfix(loss=(loss.item()*data.size(0) / (counter * train_loader.batch_size)))\n        running_loss += loss.item()\n        running_corrects += torch.sum(preds == target).item()\n        \n    epoch_loss = running_loss / len(train_loader)\n    epoch_acc = running_corrects / len(train_indices)  # Use len(train_indices) instead of len(train_loader.dataset)\n    train_loss.append(epoch_loss)\n    train_accuracy.append(epoch_acc)\n    print(epoch_loss)\n    print(epoch_acc)\n\n\ndef val(model, device, val_loader, val_indices):\n    model.eval()\n    val_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in val_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            logits = output\n            val_loss += criterion(logits, target).item() # sum up batch loss\n            pred_prob = torch.softmax(logits, dim=1) # apply softmax to output\n            pred_class = torch.argmax(pred_prob, dim=1) # get the index of the max probability\n            correct += pred_class.eq(target.view_as(pred_class)).sum().item()\n    val_acc= correct/len(val_indices)  # Use len(val_indices) instead of len(val_loader.dataset)\n    val_loss /= len(val_loader)\n    valid_loss.append(val_loss)\n    valid_accuracy.append(val_acc)\n    print(val_loss)\n    print(val_acc)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        val_loss, correct, len(val_indices),\n        100. * correct / len(val_indices)))  # Use len(val_indices) instead of len(val_loader.dataset)","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:13.567027Z","iopub.execute_input":"2023-09-11T20:06:13.567704Z","iopub.status.idle":"2023-09-11T20:06:13.588971Z","shell.execute_reply.started":"2023-09-11T20:06:13.567666Z","shell.execute_reply":"2023-09-11T20:06:13.587757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, SubsetRandomSampler\nfrom sklearn.model_selection import KFold\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nepochs = 40\nbatch_size = 64\n\ntrain_loss_per_fold = []\ntrain_accuracy_per_fold = []\nvalid_loss_per_fold = []\nvalid_accuracy_per_fold = []\n\nstart_time = time.time()\n\nfor fold, (train_indices, val_indices) in enumerate(kf.split(train_dataset)):\n    print(f\"Fold {fold + 1}/{kf.get_n_splits()}\")  # Using kf.get_n_splits() to get the number of splits\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(train_indices))\n    val_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=SubsetRandomSampler(val_indices))\n\n    for epoch in range(epochs):\n        train(model, device, train_loader, optimizer, epoch, train_indices)\n        val(model, device, val_loader, val_indices)\n\n    # Store the outputs for each fold\n    train_loss_per_fold.append(train_loss)\n    train_accuracy_per_fold.append(train_accuracy)\n    valid_loss_per_fold.append(valid_loss)\n    valid_accuracy_per_fold.append(valid_accuracy)\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n","metadata":{"execution":{"iopub.status.busy":"2023-09-11T20:06:13.590669Z","iopub.execute_input":"2023-09-11T20:06:13.591324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import time\n\nstart_time = time.time()\n\nnum_epoch = 100\nfor epoch in range(1, num_epoch + 1):\n    train(model, device, train_loader, optimizer, epoch, train_indices, val_indices)\n    val(model, device, val_loader, val_indices)\n    \n    print(\"Epoch:\", epoch)\n    \n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n","metadata":{"execution":{"iopub.status.busy":"2023-08-01T12:46:45.344631Z","iopub.execute_input":"2023-08-01T12:46:45.34501Z","iopub.status.idle":"2023-08-01T12:47:01.372173Z","shell.execute_reply.started":"2023-08-01T12:46:45.344963Z","shell.execute_reply":"2023-08-01T12:47:01.370729Z"}}},{"cell_type":"markdown","source":"# **Evaluasi Model**","metadata":{}},{"cell_type":"code","source":"# Evaluasi model pada data pengujian\nmodel.eval()\ntest_loss = 0.0\ntotal_correct = 0\ntotal_samples = 0\n\nwith torch.no_grad():\n    for batch in test_loader:\n        images, labels = batch[0].to(device), batch[1].to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        test_loss += loss.item()\n\n        _, predicted = torch.max(outputs.data, 1)\n        total_samples += labels.size(0)\n        total_correct += (predicted == labels).sum().item()\n\ntest_accuracy = total_correct / total_samples\ntest_loss /= len(test_loader)\n\n# Mencetak loss dan akurasi pada data pengujian\nprint(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_accuracy*100:.2f}%\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dictionary = {\n    'train_loss':train_loss,\n    'train_accuracy':train_accuracy,\n    'val_loss':valid_loss,\n    'val_accuracy':valid_accuracy\n}\nmetrics = pd.DataFrame(dictionary)\nmetrics","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\nfig.suptitle('Model Metrics Plots')\n\nax1.plot(metrics[['train_loss', 'val_loss']])\nax1.legend(['train_loss', 'val_loss'], loc=\"upper right\")\n\nax2.plot(metrics[['train_accuracy', 'val_accuracy']])\nax2.legend(['train_accuracy', 'val_accuracy'], loc=\"lower right\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\ny_pred = []\ny_true = []\n\nfor data, labels in test_loader:\n        data = data.to(torch.device('cuda'))\n        output = model(data) # Feed Network\n        \n        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n        y_pred.extend(output) # Save Prediction\n        \n        labels = labels.data.cpu().numpy()\n        y_true.extend(labels) # Save Truth\n\nclasses = (\"Normal\", \"Autisme\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cf_matrix = confusion_matrix(y_true, y_pred)\ndf_cm = pd.DataFrame(cf_matrix, index = [i for i in classes],\n                     columns = [i for i in classes])\nplt.figure(figsize = (12,7))\nsn.heatmap(df_cm, fmt=\"d\",annot=True)\nprint(classification_report(y_true, y_pred))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}