{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dewizunuvi/Deteksi-Autisme/blob/main/DenseNet121_fix_saved.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYZvVdNE-gAh"
      },
      "source": [
        "# **Klasifikasi MRI Autisme ResNet-50**\n",
        "Gambar Nifti diubah ke 2D, RGB, Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ65HwbuDQ2w"
      },
      "source": [
        "#### Import nibabel package to read NIfTI images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pnVExdPwDQ20"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import tensorflow as tf\n",
        "from keras import applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAdKoPKnDQ24"
      },
      "source": [
        "#### Import all the keras required library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Cp-AG3v8DQ24"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras import layers\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential, Model \n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAcW8twKDQ25"
      },
      "source": [
        "#### Fatch all the preprocessed images from the folder, preprocessing is done in SPM (matlab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR3cG2luDQ25",
        "outputId": "34d2b428-2c8f-436a-f310-2e6ab00104a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set path to folder containing NIfTI files\n",
        "folder_path_autism = \"/content/drive/MyDrive/Dataset_Autis/Autism\"\n",
        "folder_path_control = \"/content/drive/MyDrive/Dataset_Autis/Control\"\n",
        "\n",
        "# daftar file .nii.gz dari folder1\n",
        "files1 = [os.path.join(folder_path_autism, f) for f in os.listdir(folder_path_autism) if f.endswith('.nii.gz')]\n",
        "\n",
        "# daftar file .nii.gz dari folder2\n",
        "files2 = [os.path.join(folder_path_control, f) for f in os.listdir(folder_path_control) if f.endswith('.nii.gz')]\n",
        "\n",
        "# Load images from the two folders\n",
        "images1 = [nib.load(f) for f in files1]\n",
        "images2 = [nib.load(f) for f in files2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "m0OLgYXTHamh"
      },
      "outputs": [],
      "source": [
        "# Combine the two sets of images\n",
        "dataf = images1 + images2\n",
        "\n",
        "# Generate labels for the images\n",
        "labels = [1] * len(images1) + [0] * len(images2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIA951d9DQ28"
      },
      "source": [
        "#### Data Conversion from 3D to 2D and introduce 3 channels (RGB) because the predefined model always takes 2D images with 3 channels in Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XU9NK1zqDQ29"
      },
      "outputs": [],
      "source": [
        "# create an empty list to store the slice data\n",
        "slice_list = []\n",
        "\n",
        "# loop over the images and convert to 2D\n",
        "for img in images1 + images2:\n",
        "    # get the image data as a numpy array\n",
        "    data = img.get_fdata()\n",
        "    # select a slice to display (e.g. the middle slice along the first axis)\n",
        "    slice_idx = data.shape[0] // 2\n",
        "    # extract the 2D slice data\n",
        "    slice_data = data[slice_idx, :, :]\n",
        "    # add the slice data to the list\n",
        "    slice_list.append(slice_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lVBulaX9lnw",
        "outputId": "1a055a98-ae96-4b82-d2a4-c7317a062e3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1102"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(slice_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7aBhwMHVQ6UX"
      },
      "outputs": [],
      "source": [
        "data_array = np.array(slice_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysldCA8RRWev",
        "outputId": "3f5a5d5a-efed-4dc0-e58f-f53d1ccfa702"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1102, 73, 61)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "data_array.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6ZUEmVmA4pC"
      },
      "source": [
        "#Turn to RGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hZN05Y2FRg8H"
      },
      "outputs": [],
      "source": [
        "data_image=np.stack([data_array]*3, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4Sm_tmnCtjI",
        "outputId": "d4841cd1-7781-4924-e3bd-88b59fee1901"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1102, 73, 61, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "data_image.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZMFRJsGDQ2-"
      },
      "source": [
        "#### Split the data into train and test in the 70:30 ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IVfgFfp7DQ2-"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data_image, labels, test_size=0.4)\n",
        "y_train=np.array(y_train)\n",
        "\n",
        "\n",
        "input_shape = (73, 61,3)\n",
        "x_train = x_train.astype('float32')\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_old_test=y_test\n",
        "y_test = keras.utils.to_categorical(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iKy-atpDQ2-"
      },
      "source": [
        "#### Use the ResNet50 model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "6peMpAriSzlC"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "# Load the ResNet50 model\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)  # Add a dropout layer with dropout rate of 0.5\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "M1weCwbaDQ2-"
      },
      "outputs": [],
      "source": [
        "model = applications.ResNet50(weights = \"imagenet\", include_top=False, input_shape =input_shape)\n",
        "\n",
        "\n",
        "# Freeze the layers which you don't want to train. Here I am not freezing any layer.\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "#Adding custom Layers \n",
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(16, activation=\"relu\")(x)\n",
        "predictions = Dense(2, activation=\"softmax\")(x)\n",
        "model= Model(inputs = model.input, outputs = predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfdtXK7PDQ2-",
        "outputId": "decae1bc-f109-4b69-b967-8b531a4d3198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 73, 61, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 79, 67, 3)    0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 37, 31, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 37, 31, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 37, 31, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 39, 33, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 19, 16, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 19, 16, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 19, 16, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 19, 16, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 19, 16, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 19, 16, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 19, 16, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 19, 16, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 19, 16, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 19, 16, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 19, 16, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 19, 16, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 19, 16, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 19, 16, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 19, 16, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 19, 16, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 19, 16, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 19, 16, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 19, 16, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 19, 16, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 19, 16, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 19, 16, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 19, 16, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 19, 16, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 19, 16, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 19, 16, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 19, 16, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 19, 16, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 19, 16, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 19, 16, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 19, 16, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 19, 16, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 19, 16, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 10, 8, 128)   32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 10, 8, 128)  512         ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 10, 8, 128)  0           ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 10, 8, 128)   147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 10, 8, 128)  512         ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 10, 8, 128)  0           ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 10, 8, 512)   131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 10, 8, 512)   66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 10, 8, 512)  2048        ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 10, 8, 512)  2048        ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 10, 8, 512)   0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 10, 8, 512)   0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 10, 8, 128)   65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 10, 8, 128)  512         ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 10, 8, 128)  0           ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 10, 8, 128)   147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 10, 8, 128)  512         ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 10, 8, 128)  0           ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 10, 8, 512)   66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 10, 8, 512)  2048        ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 10, 8, 512)   0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 10, 8, 512)   0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 10, 8, 128)   65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 10, 8, 128)  512         ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 10, 8, 128)  0           ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 10, 8, 128)   147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 10, 8, 128)  512         ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 10, 8, 128)  0           ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 10, 8, 512)   66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 10, 8, 512)  2048        ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 10, 8, 512)   0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 10, 8, 512)   0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 10, 8, 128)   65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 10, 8, 128)  512         ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 10, 8, 128)  0           ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 10, 8, 128)   147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 10, 8, 128)  512         ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 10, 8, 128)  0           ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 10, 8, 512)   66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 10, 8, 512)  2048        ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 10, 8, 512)   0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 10, 8, 512)   0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 5, 4, 256)    131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 5, 4, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 5, 4, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 5, 4, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 5, 4, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 5, 4, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 5, 4, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                                                  'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 5, 4, 1024)   0           ['conv4_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 5, 4, 256)    262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 5, 4, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 5, 4, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 5, 4, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 5, 4, 1024)   0           ['conv4_block1_out[0][0]',       \n",
            "                                                                  'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 5, 4, 1024)   0           ['conv4_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 5, 4, 256)    262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 5, 4, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 5, 4, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 5, 4, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 5, 4, 1024)   0           ['conv4_block2_out[0][0]',       \n",
            "                                                                  'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 5, 4, 1024)   0           ['conv4_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 5, 4, 256)    262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 5, 4, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 5, 4, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 5, 4, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 5, 4, 1024)   0           ['conv4_block3_out[0][0]',       \n",
            "                                                                  'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 5, 4, 1024)   0           ['conv4_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 5, 4, 256)    262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 5, 4, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 5, 4, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 5, 4, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 5, 4, 1024)   0           ['conv4_block4_out[0][0]',       \n",
            "                                                                  'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 5, 4, 1024)   0           ['conv4_block5_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 5, 4, 256)    262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 5, 4, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 5, 4, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 5, 4, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 5, 4, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 5, 4, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 5, 4, 1024)   0           ['conv4_block5_out[0][0]',       \n",
            "                                                                  'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 5, 4, 1024)   0           ['conv4_block6_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 3, 2, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 3, 2, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 3, 2, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 3, 2, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 3, 2, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 3, 2, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 3, 2, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 3, 2, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 3, 2, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 3, 2, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 3, 2, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 3, 2, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 3, 2, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 3, 2, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 3, 2, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 3, 2, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 3, 2, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 3, 2, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 3, 2, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 3, 2, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 3, 2, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 3, 2, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 3, 2, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 3, 2, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 3, 2, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 3, 2, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 3, 2, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 3, 2, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 3, 2, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 3, 2, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 3, 2, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 3, 2, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_3 (Flatten)            (None, 12288)        0           ['conv5_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 16)           196624      ['flatten_3[0][0]']              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 2)            34          ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,784,370\n",
            "Trainable params: 23,731,250\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnVftuXDDQ2-"
      },
      "source": [
        "#### Compile and train the model with Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Wa4VsDaDQ2_",
        "scrolled": true,
        "outputId": "ed9ad5a7-d07e-4866-e767-099be94fa2ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "4/4 [==============================] - 55s 13s/step - loss: 2.1779 - accuracy: 0.4571 - val_loss: 0.6931 - val_accuracy: 0.5245\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6931 - val_accuracy: 0.5245\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6931 - val_accuracy: 0.5245\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6930 - val_accuracy: 0.5245\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.6931 - accuracy: 0.5152 - val_loss: 0.6930 - val_accuracy: 0.5245\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6930 - val_accuracy: 0.5245\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6930 - val_accuracy: 0.5245\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6929 - val_accuracy: 0.5245\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6929 - val_accuracy: 0.5245\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6929 - val_accuracy: 0.5245\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6929 - val_accuracy: 0.5245\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6929 - val_accuracy: 0.5245\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 46s 11s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6928 - val_accuracy: 0.5245\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6928 - val_accuracy: 0.5245\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6930 - accuracy: 0.5152 - val_loss: 0.6928 - val_accuracy: 0.5245\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6928 - val_accuracy: 0.5245\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6927 - val_accuracy: 0.5245\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6927 - val_accuracy: 0.5245\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6927 - val_accuracy: 0.5245\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6927 - val_accuracy: 0.5245\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6927 - val_accuracy: 0.5245\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6927 - val_accuracy: 0.5245\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6926 - val_accuracy: 0.5245\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6926 - val_accuracy: 0.5245\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 47s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6926 - val_accuracy: 0.5245\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6929 - accuracy: 0.5152 - val_loss: 0.6926 - val_accuracy: 0.5245\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6926 - val_accuracy: 0.5245\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6926 - val_accuracy: 0.5245\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6925 - val_accuracy: 0.5245\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6925 - val_accuracy: 0.5245\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 46s 12s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6925 - val_accuracy: 0.5245\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6925 - val_accuracy: 0.5245\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6925 - val_accuracy: 0.5245\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6925 - val_accuracy: 0.5245\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6925 - val_accuracy: 0.5245\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5245\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5245\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5245\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5245\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5245\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5245\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5245\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5245\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5245\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6928 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 46s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 45s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5245\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5245\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 49s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 46s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 48s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 49s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 47s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 50s 13s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 48s 12s/step - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5245\n"
          ]
        }
      ],
      "source": [
        "model.compile(keras.optimizers.Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "val=model.fit(x=x_train,y=y_train,batch_size=100, epochs=150,validation_split=0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save The Model"
      ],
      "metadata": {
        "id": "y9SbyeGiAboU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan model ke dalam file\n",
        "model.save('modelDenseNetAUTISM.h5')"
      ],
      "metadata": {
        "id": "sx37rfGJAays"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqqmUprGDQ2_"
      },
      "source": [
        "#### The model loss and accuracy on test data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eRkFGiT6DQ2_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f53a5b-7b82-4127-d2eb-9d57898e4d92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in x_test 441\n",
            "14/14 [==============================] - 5s 349ms/step - loss: 0.6926 - accuracy: 0.5170\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6925753355026245, 0.5170068144798279]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#x_test = X_test.reshape(X_test.shape[0],145,121,3)\n",
        "x_test = x_test.astype('float32')\n",
        "    # Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "print('Number of images in x_test', x_test.shape[0])\n",
        "model.evaluate(x_test,y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oeDrObPpDQ2_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "254d2a5e-7302-4b6d-eca3-dd28f0c0da33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(val.history['accuracy'])\n",
        "plt.plot(val.history['val_accuracy'])\n",
        "plt.legend(['Training accuracy' ,'Validation Accuracy'])\n",
        "plt.title(\"Train Vs Validation With ResNet\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "aQ65HwbuDQ2w",
        "EAdKoPKnDQ24"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}